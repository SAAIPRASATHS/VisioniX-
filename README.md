# VisioniX - Statistella Round 2 ML Pipeline

## ğŸ† B.A.S.H Data Analytics Competition

A complete end-to-end Machine Learning pipeline for predicting **Importance Score (0-100)** for legal documents in the Statistella Round 2 competition.

## ğŸ“‹ Project Overview

This project implements a robust ML pipeline using **LightGBM** with extensive feature engineering to predict document importance scores based on textual and categorical features.

### Key Features

- **Text Feature Engineering**: TF-IDF vectorization on document titles, keywords, and descriptions
- **Categorical Encoding**: Label encoding for categorical variables (state, court, case type)
- **Count-based Features**: Citation counts, keyword frequencies, topic distributions
- **Advanced Regression**: LightGBM with early stopping and hyperparameter tuning
- **Ensemble Ready**: Multiple model variants for potential stacking

## ğŸ“ Project Structure

```
VisioniX/
â”œâ”€â”€ bash-8-0-round-2/
â”‚   â”œâ”€â”€ train.csv           # Training dataset
â”‚   â””â”€â”€ test.csv            # Test dataset
â”œâ”€â”€ statistella_pipeline.py # Main ML pipeline
â”œâ”€â”€ statistella_improved.py # Enhanced version with additional features
â”œâ”€â”€ submission.csv          # Kaggle submission file
â”œâ”€â”€ feature_importance.png  # Feature importance visualization
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md              # This file
```

## ğŸš€ Quick Start

### Prerequisites

```bash
pip install -r requirements.txt
```

### Run the Pipeline

```bash
python statistella_pipeline.py
```

### Or use the improved version

```bash
python statistella_improved.py
```

## ğŸ“Š Model Performance

| Metric | Value |
|--------|-------|
| Best Iteration | 813 |
| Training RMSE | ~1.55 |
| Validation RMSE | ~4.04 |

## ğŸ”§ Tech Stack

- **Python 3.8+**
- **LightGBM** - Gradient Boosting Framework
- **Pandas** - Data Manipulation
- **Scikit-learn** - TF-IDF & Preprocessing
- **NumPy** - Numerical Computing
- **Matplotlib** - Visualization

## ğŸ“ˆ Feature Engineering

1. **TF-IDF Features**: Extracted from document titles, keywords, and descriptions
2. **Label Encoding**: State, court type, case type encoding
3. **Count Features**: Number of citations, keywords, topics
4. **Text Statistics**: Word counts, character lengths
5. **Frequency Features**: Keyword and topic frequencies

## ğŸ“ Output

The pipeline generates:
- `submission.csv` - Kaggle-ready predictions with ID and Importance Score
- `feature_importance.png` - Visual representation of feature importance

## ğŸ‘¨â€ğŸ’» Author

**SAAIPRASATH S**

## ğŸ“„ License

This project is for the B.A.S.H Data Analytics Competition (Statistella Round 2).

---

â­ **Star this repo if you found it helpful!**
